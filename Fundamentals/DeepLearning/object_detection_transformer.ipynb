{"cells":[{"cell_type":"markdown","metadata":{"id":"TW2HyR7ricFu"},"source":["# Oject Detection with transformer"]},{"cell_type":"markdown","metadata":{"id":"y6XFd4uWicFw"},"source":["Tutorial from : https://huggingface.co/docs/transformers/tasks/object_detection"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ExkT80pxicFx"},"outputs":[],"source":["# install related libraries\n","!pip install -q datasets transformers evaluate timm albumentations"]},{"cell_type":"markdown","metadata":{"id":"B0euspRpicFy"},"source":["# Import libraries "]},{"cell_type":"markdown","metadata":{"id":"rMPPQMLZicFy"},"source":["ที่ใช้ในการทำงาน เราจะใช้ `transformers` และ `datasets` มาช่วยในการทำงาน จาก huggingface hub"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5CFJCrvDicFy"},"outputs":[],"source":["from transformers import AutoModelForObjectDetection \n","from transformers import AutoImageProcessor\n","from transformers import TrainingArguments\n","from transformers import Trainer\n","from datasets import load_dataset\n","import torch\n","import torchvision\n","import evaluate\n","from tqdm import tqdm\n","import albumentations\n","from PIL import Image, ImageDraw\n","import requests\n","import numpy as np\n","import json\n","import os"]},{"cell_type":"markdown","metadata":{"id":"Lia5CWBNicFz"},"source":["# Preparing data"]},{"cell_type":"markdown","metadata":{"id":"rD7ZP85micFz"},"source":["Download `cppe-5` dataset เพื่อใช้ในการ train model และ test model "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lv7UeX7RicF0"},"outputs":[],"source":["cppe5 = load_dataset(\"cppe-5\")\n","cppe5"]},{"cell_type":"markdown","metadata":{"id":"3hGH8A67icF0"},"source":["สร้าง `id2label` และ `label2id` ของ dataset ที่ใช้"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B2z_s1L3icF0"},"outputs":[],"source":["categories = cppe5[\"train\"].features[\"objects\"].feature[\"category\"].names \n","id2label = {index: x for index, x in enumerate(categories, start=0)} \n","label2id = {v: k for k, v in id2label.items()} "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LfOlS_qQicF1"},"outputs":[],"source":["# remove images with no objects\n","remove_idx = [590, 821, 822, 875, 876, 878, 879] \n","keep = [i for i in range(len(cppe5[\"train\"])) if i not in remove_idx]\n","cppe5[\"train\"] = cppe5[\"train\"].select(keep)"]},{"cell_type":"markdown","metadata":{"id":"LlYXhDgBicF1"},"source":["Transform data "]},{"cell_type":"markdown","metadata":{"id":"z75T_jShicF1"},"source":["`trasnfrom` data ก่อนที่จะเข้าไปใช้ใน model โดยใช้ `albumentations` ในการทำ data augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jNxtwz3micF1"},"outputs":[],"source":["transform = albumentations.Compose(\n","    [\n","        albumentations.Resize(480, 480), # resize to 480x480\n","        albumentations.HorizontalFlip(p=1.0), # horizontal flip\n","        albumentations.RandomBrightnessContrast(p=1.0), # random brightness and contrast\n","    ],\n","    bbox_params=albumentations.BboxParams(format=\"coco\", label_fields=[\"category\"]),\n",")"]},{"cell_type":"markdown","metadata":{"id":"yfYiADD9icF2"},"source":["define function สำหรับการ train model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y8xcLUmEicF2"},"outputs":[],"source":["# formatted annotations\n","def formatted_anns(image_id, category, area, bbox): \n","    annotations = []\n","    for i in range(0, len(category)):\n","        new_ann = {\n","            \"image_id\": image_id,\n","            \"category_id\": category[i],\n","            \"isCrowd\": 0,\n","            \"area\": area[i],\n","            \"bbox\": list(bbox[i]),\n","        }\n","        annotations.append(new_ann)\n","\n","    return annotations\n","\n","# transforming a batch\n","def transform_aug_ann(examples):\n","    image_ids = examples[\"image_id\"]\n","    images, bboxes, area, categories = [], [], [], []\n","    for image, objects in zip(examples[\"image\"], examples[\"objects\"]):\n","        image = np.array(image.convert(\"RGB\"))[:, :, ::-1]\n","        out = transform(image=image, bboxes=objects[\"bbox\"], category=objects[\"category\"])\n","\n","        area.append(objects[\"area\"])\n","        images.append(out[\"image\"])\n","        bboxes.append(out[\"bboxes\"])\n","        categories.append(out[\"category\"])\n","\n","    targets = [\n","        {\"image_id\": id_, \"annotations\": formatted_anns(id_, cat_, ar_, box_)}\n","        for id_, cat_, ar_, box_ in zip(image_ids, categories, area, bboxes)\n","    ]\n","\n","    return image_processor(images=images, annotations=targets, return_tensors=\"pt\")\n","\n","def collate_fn(batch):\n","    pixel_values = [item[\"pixel_values\"] for item in batch]\n","    encoding = image_processor.pad_and_create_pixel_mask(pixel_values, return_tensors=\"pt\")\n","    labels = [item[\"labels\"] for item in batch]\n","    batch = {}\n","    batch[\"pixel_values\"] = encoding[\"pixel_values\"]\n","    batch[\"pixel_mask\"] = encoding[\"pixel_mask\"]\n","    batch[\"labels\"] = labels\n","    return batch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SQ6ygSLsicF2"},"outputs":[],"source":["# trainfrom cppe5 model with augmentation\n","cppe5[\"train\"] = cppe5[\"train\"].with_transform(transform_aug_ann)"]},{"cell_type":"markdown","metadata":{"id":"ux8tcBFficF2"},"source":["# Train model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oDL6KJvCicF3"},"outputs":[],"source":["# เลือก pretrain_model และ image processor ที่จะใช้\n","checkpoint = \"facebook/detr-resnet-50\" \n","image_processor = AutoImageProcessor.from_pretrained(checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J2yowGT9icF3"},"outputs":[],"source":["# สร้าง model จาก pretrain_model ที่เลือก\n","model = AutoModelForObjectDetection.from_pretrained(\n","    checkpoint,\n","    id2label=id2label,\n","    label2id=label2id,\n","    ignore_mismatched_sizes=True,\n",")"]},{"cell_type":"markdown","metadata":{"id":"Eai6qlsDicF3"},"source":["กำหนด `training_args` และ `trainer` สำหรับการเทรนโมเดล"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"snpyMxr-icF3"},"outputs":[],"source":["# [optional] disable wandb ที่ใช้ในการ log ข้อมูล\n","os.environ[\"WANDB_DISABLED\"] = \"true\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EdYlWet5icF3"},"outputs":[],"source":["training_args = TrainingArguments(\n","    output_dir=\"{directory_name}\", # ชื่อโฟลเดอร์ที่เราจะเก็บ model ที่ train ได้\n","    per_device_train_batch_size=2, # จำนวน batch size \n","    num_train_epochs=10,  # จำนวน epoch ที่เราต้องการให้โมเดล train\n","    fp16=True, # ใช้ mixed precision หรือไม่\n","    save_steps=200, # จำนวน step ที่เราต้องการให้โมเดล save\n","    logging_steps=50, \n","    learning_rate=1e-5, # ค่า learning rate\n","    weight_decay=1e-4, # ค่า weight decay\n","    save_total_limit=2, # จำนวน model ที่เราต้องการให้โมเดล save\n","    remove_unused_columns=False, \n","    push_to_hub=False, \n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ue4C0E6FicF3"},"outputs":[],"source":["# สร้าง trainer จาก model ที่เราสร้างไว้\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=collate_fn,\n","    train_dataset=cppe5[\"train\"],\n","    tokenizer=image_processor,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kSTW_OVoicF4"},"outputs":[],"source":["trainer.train() # train model"]},{"cell_type":"markdown","metadata":{"id":"G_9HxmpcicF4"},"source":["# Evaluation"]},{"cell_type":"markdown","metadata":{"id":"UYA5mJcZicF4"},"source":["ทดสอบ model หรือ `evaluation` เพื่อเช็คผลลัพธ์ของโมเดล "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ES49b1Y-icF4"},"outputs":[],"source":["class CocoDetection(torchvision.datasets.CocoDetection):\n","    def __init__(self, img_folder, feature_extractor, ann_file):\n","        super().__init__(img_folder, ann_file)\n","        self.feature_extractor = feature_extractor\n","\n","    def __getitem__(self, idx):\n","        # read in PIL image and target in COCO format\n","        img, target = super(CocoDetection, self).__getitem__(idx)\n","\n","        # preprocess image and target: converting target to DETR format,\n","        # resizing + normalization of both image and target\n","        image_id = self.ids[idx]\n","        target = {\"image_id\": image_id, \"annotations\": target}\n","        encoding = self.feature_extractor(images=img, annotations=target, return_tensors=\"pt\")\n","        pixel_values = encoding[\"pixel_values\"].squeeze()  # remove batch dimension\n","        target = encoding[\"labels\"][0]  # remove batch dimension\n","\n","        return {\"pixel_values\": pixel_values, \"labels\": target}\n","\n","\n","# format annotations the same as for training, no need for data augmentation\n","def val_formatted_anns(image_id, objects):\n","    annotations = []\n","    for i in range(0, len(objects[\"id\"])):\n","        new_ann = {\n","            \"id\": objects[\"id\"][i],\n","            \"category_id\": objects[\"category\"][i],\n","            \"iscrowd\": 0,\n","            \"image_id\": image_id,\n","            \"area\": objects[\"area\"][i],\n","            \"bbox\": objects[\"bbox\"][i],\n","        }\n","        annotations.append(new_ann)\n","\n","    return annotations\n","\n","\n","# Save images and annotations into the files torchvision.datasets.CocoDetection expects\n","def save_cppe5_annotation_file_images(cppe5):\n","    output_json = {}\n","    path_output_cppe5 = f\"{os.getcwd()}/cppe5/\"\n","\n","    if not os.path.exists(path_output_cppe5):\n","        os.makedirs(path_output_cppe5)\n","\n","    path_anno = os.path.join(path_output_cppe5, \"cppe5_ann.json\")\n","    categories_json = [{\"supercategory\": \"none\", \"id\": id, \"name\": id2label[id]} for id in id2label]\n","    output_json[\"images\"] = []\n","    output_json[\"annotations\"] = []\n","    for example in cppe5:\n","        ann = val_formatted_anns(example[\"image_id\"], example[\"objects\"])\n","        output_json[\"images\"].append(\n","            {\n","                \"id\": example[\"image_id\"],\n","                \"width\": example[\"image\"].width,\n","                \"height\": example[\"image\"].height,\n","                \"file_name\": f\"{example['image_id']}.png\",\n","            }\n","        )\n","        output_json[\"annotations\"].extend(ann)\n","    output_json[\"categories\"] = categories_json\n","\n","    with open(path_anno, \"w\") as file:\n","        json.dump(output_json, file, ensure_ascii=False, indent=4)\n","\n","    for im, img_id in zip(cppe5[\"image\"], cppe5[\"image_id\"]):\n","        path_img = os.path.join(path_output_cppe5, f\"{img_id}.png\")\n","        im.save(path_img)\n","\n","    return path_output_cppe5, path_anno"]},{"cell_type":"markdown","metadata":{"id":"m9d2wCavicF4"},"source":["เลือก `model` ที่เราใช้ในการ evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UZ-3UdIOicF5"},"outputs":[],"source":["model_path = \"{directory_name}/{model}\" # ใส่ directory ของ model ที่เราเทรนไว้"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kBixCP7micF5"},"outputs":[],"source":["# เลือก processor จาก model ที่เรา train ไว้\n","im_processor = AutoImageProcessor.from_pretrained(f\"{model_path}/preprocessor_config.json\", local_files_only=True)\n","path_output_cppe5, path_anno = save_cppe5_annotation_file_images(cppe5[\"test\"])\n","test_ds_coco_format = CocoDetection(path_output_cppe5, im_processor, path_anno)\n","\n","# เลือก model ที่เรา train ไว้\n","model = AutoModelForObjectDetection.from_pretrained(f\"{model_path}\", local_files_only=True)\n","module = evaluate.load(\"ybelkada/cocoevaluate\", coco=test_ds_coco_format.coco)\n","val_dataloader = torch.utils.data.DataLoader(\n","    test_ds_coco_format, batch_size=2, shuffle=False, num_workers=0, collate_fn=collate_fn\n",")\n","\n","# prediction และ evaluation\n","with torch.no_grad():\n","    for idx, batch in enumerate(tqdm(val_dataloader)):\n","        pixel_values = batch[\"pixel_values\"]\n","        pixel_mask = batch[\"pixel_mask\"]\n","\n","        labels = [\n","            {k: v for k, v in t.items()} for t in batch[\"labels\"]\n","        ]  # these are in DETR format, resized + normalized\n","\n","        # forward pass\n","        outputs = model(pixel_values=pixel_values, pixel_mask=pixel_mask)\n","\n","        orig_target_sizes = torch.stack([target[\"orig_size\"] for target in labels], dim=0)\n","        results = im_processor.post_process(outputs, orig_target_sizes)  # convert outputs of model to COCO api\n","\n","        module.add(prediction=results, reference=labels)\n","        del batch\n","\n","results = module.compute()\n","\n","# แสดงผล evaluation\n","print(results)"]},{"cell_type":"markdown","metadata":{"id":"IcdUGFmZicF5"},"source":["# Inference"]},{"cell_type":"markdown","metadata":{"id":"8qt22yTZicF5"},"source":["Prediction `inference` โดยใช้ `model` ที่เรา train ไว้"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oXtI9SnEicF5"},"outputs":[],"source":["# เลือกรูปที่ต้องการ predict จาก url\n","url = \"https://i.imgur.com/2lnWoly.jpg\"\n","image = Image.open(requests.get(url, stream=True).raw)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TqfUHL4micF6"},"outputs":[],"source":["model_path = \"{directory_name}/{model}\" # ใส่ directory ของ model ที่เราเทรนไว้"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vNgL8RVDicF6"},"outputs":[],"source":["image_processor = AutoImageProcessor.from_pretrained(f\"{model_path}/preprocessor_config.json\", local_files_only=True)  # processor \n","model = AutoModelForObjectDetection.from_pretrained(f\"{model_path}\", local_files_only=True) # model \n","\n","# predict image\n","with torch.no_grad():\n","    inputs = image_processor(images=image, return_tensors=\"pt\")\n","    outputs = model(**inputs)\n","    target_sizes = torch.tensor([image.size[::-1]])\n","    results = image_processor.post_process_object_detection(outputs, threshold=0.5, target_sizes=target_sizes)[0] # ใส่ threshold ที่เหมาะสม "]},{"cell_type":"markdown","metadata":{"id":"J8qTE6jKicF6"},"source":["`thesold` เราสามารถเปลี่ยนค่าได้ตามความเหมาะสม เนื่องจากในบาง model ที่เราเทรนไว้ จะมีค่า confidence ของการ `prediction` ที่ต่างกัน"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g8jU0wcNicF6"},"outputs":[],"source":["# visualize results\n","for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n","    box = [round(i, 2) for i in box.tolist()]\n","    print(\n","        f\"Detected {model.config.id2label[label.item()]} with confidence \"\n","        f\"{round(score.item(), 3)} at location {box}\"\n","    )"]},{"cell_type":"markdown","metadata":{"id":"evzROYEZicF6"},"source":["Visualize prediction โดยใช้ `ImageDraw` "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7jGv8d56icF6"},"outputs":[],"source":["draw = ImageDraw.Draw(image)\n","\n","for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n","    box = [round(i, 2) for i in box.tolist()]\n","    x, y, x2, y2 = tuple(box)\n","    draw.rectangle((x, y, x2, y2), outline=\"red\", width=1)\n","    draw.text((x, y), model.config.id2label[label.item()], fill=\"white\")\n","\n","image"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"orig_nbformat":4,"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}